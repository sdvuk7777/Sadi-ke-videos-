import loggingimport osimport requestsimport itertoolsfrom telegram import Update, InlineKeyboardButton, InlineKeyboardMarkupfrom telegram.ext import (    CommandHandler,    ConversationHandler,    MessageHandler,    CallbackQueryHandler,    ContextTypes,    filters,)from config import LOG_GROUP_ID  # Import LOG_GROUP_ID from config# ConstantsROOT_DIR = os.getcwd()# Stages for ConversationHandlerAUTH_CODE, BATCH_ID, SUBJECT_IDS = range(3)# Helper Functionsdef get_batches(auth_code):    """Fetch batches using the provided token."""    headers = {        'authorization': f"Bearer {auth_code}",        'client-id': '5eb393ee95fab7468a79d189',        'user-agent': 'Android',    }    result = ""    try:        for page in itertools.count(1):            response = requests.get(                f'https://api.penpencil.xyz/v3/batches/my-batches?page={page}&mode=1',                headers=headers,            )            if response.status_code == 401:                raise ValueError("Invalid or expired token")            if response.status_code != 200:                logging.error(f"Failed to fetch batches. Status code: {response.status_code}")                break            data = response.json().get("data", [])            if not data:                break            for batch in data:                batch_id = batch["_id"]                name = batch["name"]                price = batch.get("feeId", {}).get("total", "Free")                result += f"ğ‘©ğ’‚ğ’•ğ’„ğ’‰ ğ‘°ğ‘«ğŸ’¡: ```{batch_id}```\nğ‘©ğ’‚ğ’•ğ’„ğ’‰ ğ‘µğ’‚ğ’ğ’†ğŸ˜¶â€ğŸŒ«ï¸: ```{name}```\nâ“…ï¸â“‡ï¸â’¾ï¸â’¸ï¸â’ºï¸ğŸ¤‘: ```{price}```\n\n"    except ValueError as ve:        logging.error(f"Token Error: {ve}")        return "TOKEN_ERROR"    except Exception as e:        logging.error(f"Unexpected Error: {e}")        return None    return resultdef get_subjects(batch_id, auth_code):    headers = {        'authorization': f"Bearer {auth_code}",        'client-id': '5eb393ee95fab7468a79d189',        'user-agent': 'Android',    }    response = requests.get(f'https://api.penpencil.xyz/v3/batches/{batch_id}/details', headers=headers)    if response.status_code == 200:        data = response.json().get("data", {})        return data.get("subjects", [])    else:        logging.error(f"Failed to fetch subjects. Status code: {response.status_code}")        return []def get_batch_contents(batch_id, subject_id, page, auth_code, content_type):    headers = {        'authorization': f"Bearer {auth_code}",        'client-id': '5eb393ee95fab7468a79d189',        'user-agent': 'Android',    }    params = {'page': page, 'contentType': content_type}    response = requests.get(        f'https://api.penpencil.xyz/v2/batches/{batch_id}/subject/{subject_id}/contents',        params=params,        headers=headers,    )    if response.status_code == 200:        return response.json().get("data", [])    else:        logging.error(f"Failed to fetch batch contents. Status code: {response.status_code}")        return []def save_batch_contents(batch_name, subject_name, subject_data):    filename = f"{batch_name}_{subject_name}.txt"    file_path = os.path.join(ROOT_DIR, filename)    with open(file_path, 'a', encoding='utf-8') as file:        for data in subject_data:            file.write(f"{data['title']}: {data['url']}\n")    logging.info(f"Contents saved to {file_path}")    return file_path# Bot Handlersasync def pw_start(update: Update, context: ContextTypes.DEFAULT_TYPE):    await update.message.reply_text("ğ•Šğ•–ğ•Ÿğ•• ğ•ªğ• ğ•¦ğ•£ â„™ğ• ğ•’ğ•¦ğ•¥ğ•™ğ•–ğ•Ÿğ•¥ğ•šğ•”ğ•’ğ•¥ğ•šğ• ğ•Ÿ ğ•”ğ• ğ••ğ•–ğŸ˜—[ğ•‹ğ• ğ•œğ•–ğ•Ÿ]:")    return AUTH_CODEasync def handle_auth_code(update: Update, context: ContextTypes.DEFAULT_TYPE):    auth_code = update.message.text.strip()    context.user_data['auth_code'] = auth_code    await update.message.reply_text("ğ…ğğ­ğœğ¡ğ¢ğ§ğ  ğ˜ğ¨ğ®ğ« ğğšğ­ğœğ¡ğğ¬. ğğ¥ğğšğ¬ğ ğ–ğšğ¢ğ­âœ‹...")    batches = get_batches(auth_code)    if batches == "TOKEN_ERROR":        await update.message.reply_text("ğˆğ§ğ¯ğšğ¥ğ¢ğ ğ¨ğ« ğ„ğ±ğ©ğ¢ğ«ğğ ğ“ğ¨ğ¤ğğ§. ğğ¥ğğšğ¬ğ ğğ«ğ¨ğ¯ğ¢ğğ ğ€ ğ•ğšğ¥ğ¢ğ ğ“ğ¨ğ¤ğğ§ğŸ‘€.")        return ConversationHandler.END    if not batches.strip():        await update.message.reply_text("No batches found or failed to fetch. Please check your token.")        return ConversationHandler.END    await update.message.reply_text(        f"ğ’€ğ’ğ’–ğ’“ ğ‘©ğ’‚ğ’•ğ’„ğ’‰ğ’†ğ’”ğŸ˜‰:\n\n{batches}\n\nğ‘ºğ’†ğ’ğ’… ğ’•ğ’‰ğ’† ğ‘©ğ’‚ğ’•ğ’„ğ’‰ ğ‘°ğ‘« ğ‘»ğ‘¶ ğ‘·ğ’“ğ’ğ’„ğ’†ğ’†ğ’…â³:",        parse_mode="Markdown",    )    return BATCH_IDasync def handle_batch_id(update: Update, context: ContextTypes.DEFAULT_TYPE):    batch_id = update.message.text.strip()    context.user_data['batch_id'] = batch_id    auth_code = context.user_data['auth_code']    subjects = get_subjects(batch_id, auth_code)    if not subjects:        await update.message.reply_text("ğ‘ğ‘œ ğ‘ ğ‘¢ğ‘ğ‘—ğ‘’ğ‘ğ‘¡ğ‘  ğ‘“ğ‘œğ‘¢ğ‘›ğ‘‘ ğ‘“ğ‘œğ‘Ÿ ğ‘¡â„ğ‘–ğ‘  ğ‘ğ‘ğ‘¡ğ‘â„.")        return ConversationHandler.END    subject_list = "\n".join([f"```{subject['_id']}```: ```{subject['subject']}```" for subject in subjects])    await update.message.reply_text(        f"ğš‚ğšğš‹ğš“ğšğšŒğšğšœ ğšğš˜ğšğš—ğš:\n{subject_list}\n\nğš‚ğšğš—ğš ğšğš‘ğš ğš‚ğšğš‹ğš“ğšğšŒğš ğ™¸ğ™³(s) to fetch contents (separate multiple IDs with '&'):"    )    return SUBJECT_IDSasync def handle_subject_ids(update: Update, context: ContextTypes.DEFAULT_TYPE):    context.user_data['subject_ids'] = update.message.text.strip().split('&')    keyboard = [        [            InlineKeyboardButton("Exercises", callback_data="exercises-notes-videos"),            InlineKeyboardButton("Notes", callback_data="notes"),        ],        [            InlineKeyboardButton("DppNotes", callback_data="DppNotes"),            InlineKeyboardButton("DppSolution", callback_data="DppSolution"),        ],    ]    reply_markup = InlineKeyboardMarkup(keyboard)    await update.message.reply_text("Choose the type of content to extract:", reply_markup=reply_markup)async def extract_content(update: Update, context: ContextTypes.DEFAULT_TYPE):    query = update.callback_query    await query.answer()    content_type = query.data    auth_code = context.user_data['auth_code']    batch_id = context.user_data['batch_id']    subject_ids = context.user_data['subject_ids']    await query.edit_message_text(f"Extracting content type: {content_type}. Please wait...")    for subject_id in subject_ids:        page = 1        processed_data = []        while True:            subject_data = get_batch_contents(batch_id, subject_id, page, auth_code, content_type)            if not subject_data:                break            if content_type == "exercises-notes-videos":                for item in subject_data:                    processed_data.append({'title': item['topic'], 'url': item['url'].strip()})            elif content_type == "notes":                for item in subject_data:                    if item.get('homeworkIds'):                        homework = item['homeworkIds'][0]                        if homework.get('attachmentIds'):                            attachment = homework['attachmentIds'][0]                            processed_data.append({                                'title': homework['topic'],                                'url': attachment['baseUrl'] + attachment['key']                            })            elif content_type == "DppNotes":                for item in subject_data:                    if item.get('homeworkIds'):                        for homework in item['homeworkIds']:                            if homework.get('attachmentIds'):                                attachment = homework['attachmentIds'][0]                                processed_data.append({                                    'title': homework['topic'],                                    'url': attachment['baseUrl'] + attachment['key']                                })            elif content_type == "DppSolution":                for item in subject_data:                    url = item['url'].replace("d1d34p8vz63oiq", "d26g5bnklkwsh4").replace("mpd", "m3u8").strip()                    processed_data.append({'title': item['topic'], 'url': url})            page += 1        if processed_data:            subject_name = f"Subject_{subject_id}"            file_path = save_batch_contents(batch_id, subject_name, processed_data)            with open(file_path, 'rb') as file:                await query.message.reply_document(file, caption=f"Content extracted for: {subject_name}")            os.remove(file_path)        else:            await query.message.reply_text(f"No content found for Subject ID: {subject_id}.")# Add Handlers to the Dispatcherpw_handler = ConversationHandler(    entry_points=[CommandHandler("pw", pw_start)],    states={        AUTH_CODE: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_auth_code)],        BATCH_ID: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_batch_id)],        SUBJECT_IDS: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_subject_ids)],    },    fallbacks=[],)callback_handler = CallbackQueryHandler(extract_content)